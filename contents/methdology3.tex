\chapter{Value 感知的分组量化压缩策略}
完成层间秩分配只是降低 KV 缓存体积的第一步；若希望进一步压缩，就必须引入低比特量化。然而从既有实验（见表~\ref{tab:value-quant-granularity}）可以看到，简单地把 Key/Value 统一量化到 2-bit 会导致显著的性能退化，尤其是 Value 分支，其语义表达对量化噪声更为敏感。过粗的逐通道量化粒度会把大量不相关秩绑在一起，从而在 Value 上产生不可逆的精度损失；更细的组内量化虽然可以显著缓解下降，但又受限于不同层、不同秩组合下特征维度无法整除 group-size 的现实。如何在“继续压缩 KV 缓存”与“维持 Value 侧表达能力”之间取得平衡，成为我们方法第三部分需要解决的核心矛盾。