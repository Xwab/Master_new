\chapter{低秩感知的混合精度多粒度量化策略}
完成层间秩分配只是降低 KV 缓存体积的第一步；若希望进一步压缩，就必须引入低比特量化。然而已有实验（见表~\ref{tab:value-quant-granularity}）表明：当 Key/Value 被粗粒度地统一压到 2-bit 时，模型困惑度急剧上升，而 Value 分支因语义表达更敏感，退化尤为明显，提示我们需要比逐通道更细的量化粒度。其次，一旦把量化与低秩裁剪结合，层与层之间保留的 rank 彼此不同，group-wise 量化的组大小往往无法整除各自的特征维度，导致细粒度量化难以落地。最后，即使解决了粒度问题，我们仍需在不同秩之间区别对待量化精度：低秩分解所暴露的奇异值能量差异意味着重要秩必须维持较高精度，而长尾秩则可采用更低比特。如何在这三重约束下，把“粗/细粒度量化”与“混合精度、低秩感知”协同起来，构成了本章方法的出发点。

\begin{table}[htbp]
    \centering
    \caption{不同量化粒度在 2-bit 下的困惑度（Perplexity）对比}
    \label{tab:value-quant-granularity}
    \begin{tabular}{lcc}
        \toprule
        \textbf{量化粒度} & \textbf{WikiText-2} & \textbf{PTB} \\
        \midrule
        通道级（channel-wise, 2-bit） & 514.59 & 2665.66 \\
        分组级（group-wise, 2-bit） & 11.17 & 20.87 \\
        \bottomrule
    \end{tabular}
\end{table}

\section{量化基础与离群挑战}
在将 KV 缓存从浮点表示压缩到 $b$ 比特整数表示时，我们通常对每个量化单元（可对应整层、单个通道或一个 group）估计一个放缩系数 $s$ 与可选的零点 $z$，使得
\[
    q = \operatorname{clip}\!\left(\left\lfloor \frac{x}{s} + z \right\rceil, q_{\min}, q_{\max}\right), \qquad
    \hat{x} = s \cdot (q - z),
\]
其中 $x$ 与 $\hat{x}$ 分别表示原始与反量化值，$q$ 为整数码字。若 $z=0$ 并强制 $q_{\min}=-q_{\max}$，即得到\textbf{对称量化}；其实现简单、硬件友好，但需要数据分布在零点附近且正负范围大致相当。相比之下，\textbf{非对称量化}允许 $z\neq 0$，通常以数据的最小值对齐零点，从而更好地覆盖偏移分布，是移动端推理中常见的方案。

然而，无论采用哪种策略，离群值（outlier）都会显著放大量化误差。若采用单一尺度 $s$ 覆盖所有值，少量幅值巨大的 KV 元素会迫使尺度增大，从而让绝大多数常规值落在更粗的量化间隔内，最终抬高困惑度；若强行截断离群值，又会在反量化时产生饱和失真。图~\ref{fig:kv-outliers} 将展示我们在实际 KV 缓存中观测到的离群现象：少量特征维度的绝对值远高于其余维度，这正是粗粒度量化在 Value 分支上退化严重的根源，也进一步强调了需要结合细粒度划分与混合精度策略来抑制离群带来的损失。

\subsection{Hadamard 变换与离群抑制}
为缓解上述离群幅值导致的动态范围膨胀，一类常见手段是在量化前施加 Hadamard 变换。Hadamard 矩阵 $H_n\in\{\pm 1\}^{n\times n}$ 是一族正交矩阵，满足 $H_n H_n^\top = n I$，其变换可通过快速 Walsh–Hadamard 变换（FWHT）在 $O(n\log n)$ 时间内完成，不涉及乘法，仅需加减法与轻量的缩放。我们对单个量化单元的向量 $x\in\mathbb{R}^n$ 施加标准化后的变换
\[
    \tilde{x} = \frac{1}{\sqrt{n}} H_n x,
\]
然后在 $\tilde{x}$ 空间执行量化。由于 Hadamard 变换实质上把每一维度投影到 $\pm 1$ 组合的正交基上，原本集中于少数维度的能量会被“打散”至各通道，极大地降低单个维度的峰度（kurtosis），从而使可用的量化尺度更贴近大多数数值。推理阶段只需在反量化后施加同样的 Hadamard（其自身就是逆变换），即可还原到原始基底。

尽管 Hadamard 变换无法完全消除异常值，它显著降低了极端值对量化尺度的牵制，尤其适合配合细粒度 group-wise 方案使用：在每个组内独立执行 FWHT，可在可接受的算力成本下换取更平滑的值分布。但该方法也带来额外的访存与延迟开销，且若组大小与 Hadamard 阶数不匹配，需要通过零填充或子矩阵拼接来适配，这些实现细节将在后续方法部分讨论。